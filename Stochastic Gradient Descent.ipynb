{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load(r\"D:\\WPI\\Academics\\Deep_Learning\\Deep-Learning-Projects\\Project_3\\fashion_mnist_train_images.npy\")\n",
    "y_train = np.load(r\"D:\\WPI\\Academics\\Deep_Learning\\Deep-Learning-Projects\\Project_3\\fashion_mnist_train_labels.npy\").reshape(-1,1)\n",
    "Xtest = np.load(r\"D:\\WPI\\Academics\\Deep_Learning\\Deep-Learning-Projects\\Project_3\\fashion_mnist_test_images.npy\")\n",
    "ytest = np.load(r\"D:\\WPI\\Academics\\Deep_Learning\\Deep-Learning-Projects\\Project_3\\fashion_mnist_test_labels.npy\").reshape(-1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 40200) (40200, 1)\n",
      "(784, 19800) (19800, 1)\n"
     ]
    }
   ],
   "source": [
    "Xtrain, Xvalid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.33, random_state=42)\n",
    "Xtrain = np.transpose(Xtrain)\n",
    "Xvalid = np.transpose(Xvalid)\n",
    "\n",
    "print(Xtrain.shape, y_train.shape)\n",
    "print(Xvalid.shape, y_valid.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40200, 10)\n",
      "(19800, 10)\n"
     ]
    }
   ],
   "source": [
    "def one_hot_encoder(Y):   \n",
    "    ohe_train = np.zeros((Y.shape[0], 10))\n",
    "    for k, (i, j) in enumerate(zip(range(ohe_train.shape[0]), range(Y.shape[0]))):\n",
    "        # if k < 5:    \n",
    "            ohe_train[j, Y[i]] = 1\n",
    "\n",
    "    return ohe_train\n",
    "\n",
    "ytrain = one_hot_encoder(y_train)\n",
    "print(ytrain.shape)\n",
    "yvalid = one_hot_encoder(y_valid)\n",
    "ytest = one_hot_encoder(ytest)\n",
    "print(yvalid.shape)\n",
    "\n",
    "##Random initializations for hyper-parameters\n",
    "# w = np.zeros((Xtrain.shape[0],ytrain.shape[1]))\n",
    "# for i in range(w.shape[0]):\n",
    "#     for j in range(w.shape[1]):\n",
    "#         w[i,j] = np.random.randint(-10,10)\n",
    "w = np.random.randn(Xtrain.shape[0], ytrain.shape[1]) * 0.01\n",
    "\n",
    "\n",
    "bias = np.random.random(10)\n",
    "num_epoch = [1,2,3,4]\n",
    "epsilon = [0.000003,0.000004,0.000005,0.000006]\n",
    "alpha = [2,3,7,5]\n",
    "mini_batch_size = [75,25,50,100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xtrain = (784, 40200) \n",
      "ytrain = (40200, 10) \n",
      "weights = (784, 10)\n"
     ]
    }
   ],
   "source": [
    "print(f'Xtrain = {Xtrain.shape} \\nytrain = {ytrain.shape} \\nweights = {w.shape}')\n",
    "\n",
    "# def softmax1(z):\n",
    "#     exp = np.exp(z - np.max(z))\n",
    "#     ans = np.zeros_like(exp)\n",
    "#     for i in range(len(z)):\n",
    "#         ans[i] = exp[i]/np.sum(exp)\n",
    "\n",
    "#     return ans \n",
    "\n",
    "def softmax1(z):\n",
    "    exp = np.exp(z - np.max(z, axis=0))\n",
    "    return exp / np.sum(exp, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "def grad_w(X, w, Y, b, alpha):\n",
    "    y =  X.T @ w + b\n",
    "    ypred = softmax1(y)\n",
    "    yhat = ypred - Y\n",
    "    # print(ypred.shape, Y.shape)\n",
    "    reg = (alpha* w)/X.shape[1]\n",
    "    error = (np.dot(X, yhat)/X.shape[1]) + reg\n",
    "    return error \n",
    "\n",
    "def grad_b(X, w, Y, b):\n",
    "    y =  X.T @ w + b\n",
    "    ypred = softmax1(y)\n",
    "    yhat = ypred - Y\n",
    "    error = np.mean(yhat)\n",
    "    return error\n",
    "\n",
    "def Fce(X, w, Y, b, alpha):\n",
    "    z = np.dot(X.T,w)+b\n",
    "    # # print(z)\n",
    "    # exp_Z = np.exp(z)\n",
    "    # # print(exp_Z)\n",
    "    # exp_Z_mean = np.reshape(np.sum(exp_Z, axis=1), (-1, 1))\n",
    "    # Yhat = exp_Z / (exp_Z_mean + 1e-10)\n",
    "    Z=np.dot(X.T,w)+b        \n",
    "    exp_Z=np.exp(Z)   \n",
    "    exp_Z_mean=np.reshape(np.sum(exp_Z,axis=1),(-1,1))\n",
    "    Yhat=exp_Z/ (exp_Z_mean + 1e-10)\n",
    "    # Yhat = softmax1(z)\n",
    "    logYhat = np.log(Yhat)\n",
    "    loss = -np.sum(Y * logYhat) / X.shape[1]\n",
    "    return loss\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "def SGD(epoch, lr, alpha, mb, Xtrain, w, b):\n",
    "    for k,ep in enumerate(range(epoch)):\n",
    "        # if k < 2:\n",
    "            mini_batch_size = Xtrain.shape[1]/mb\n",
    "            start = 0\n",
    "            # print(mini_batch_size)\n",
    "            end = int(mini_batch_size)\n",
    "            for i in range(mb):\n",
    "                # print(i)    \n",
    "                X = Xtrain[:, start:end]\n",
    "                Y = ytrain[start:end,:]\n",
    "                # print(\"hji\",X.shape)\n",
    "                dw = grad_w(X, w, Y, b, alpha)\n",
    "                db = grad_b(X, w, Y, b)\n",
    "                # print(\"dw\", dw, db)\n",
    "\n",
    "                new_w = w - np.dot(lr,dw)\n",
    "                new_b = b - np.dot(lr,db)\n",
    "                # print(new_w, new_b)\n",
    "\n",
    "                start = end\n",
    "                end = end + int(mini_batch_size)\n",
    "\n",
    "                w = new_w\n",
    "                b = new_b\n",
    "\n",
    "            Fce_per_epoch = Fce(X, w, Y, b, alpha)\n",
    "            reg_term = (alpha/2)*(np.sum(np.dot(w.T,w)))\n",
    "            Fce_per_epoch+=reg_term\n",
    "            print(f\"Fce per epoch is={Fce_per_epoch}\")\n",
    "\n",
    "    return Fce_per_epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(epochs, lr, alphas, mini_batch, Xtrain, w, b):\n",
    "    for e in epochs:\n",
    "        for lrs in lr:\n",
    "            for alpha in alphas:\n",
    "                for mb in mini_batch:\n",
    "                    SGD(e, lrs, alpha, mb, Xtrain, w, b) #f, w, b = \n",
    "\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fce per epoch is=43.17211330336208\n",
      "Fce per epoch is=38.43370571751031\n",
      "Fce per epoch is=41.35467263670466\n",
      "Fce per epoch is=46.08017874585924\n",
      "Fce per epoch is=47.18655966081804\n",
      "Fce per epoch is=41.557006667965844\n",
      "Fce per epoch is=44.80216211103572\n",
      "Fce per epoch is=50.88805780944525\n",
      "Fce per epoch is=49.695564896533156\n",
      "Fce per epoch is=43.50906743387722\n",
      "Fce per epoch is=46.956833287131595\n",
      "Fce per epoch is=53.89293541442852\n",
      "Fce per epoch is=44.67753616535911\n",
      "Fce per epoch is=39.60494411119061\n",
      "Fce per epoch is=42.64748343851233\n",
      "Fce per epoch is=47.88314419702822\n",
      "Fce per epoch is=47.07614181964462\n",
      "Fce per epoch is=38.858589545869336\n",
      "Fce per epoch is=43.828582170441194\n",
      "Fce per epoch is=51.896904390370956\n",
      "Fce per epoch is=51.92212517902499\n",
      "Fce per epoch is=42.0629367706054\n",
      "Fce per epoch is=47.63898609496168\n",
      "Fce per epoch is=58.17760756012517\n",
      "Fce per epoch is=54.950829542721\n",
      "Fce per epoch is=44.06565064868975\n",
      "Fce per epoch is=50.0204748808623\n",
      "Fce per epoch is=62.10297316364737\n",
      "Fce per epoch is=48.89339371081836\n",
      "Fce per epoch is=40.060220479155575\n",
      "Fce per epoch is=45.25748679604944\n",
      "Fce per epoch is=54.252185127843035\n",
      "Fce per epoch is=51.257213605592526\n",
      "Fce per epoch is=39.62376187773408\n",
      "Fce per epoch is=46.54634507011461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Venk\\AppData\\Local\\Temp/ipykernel_15528/3900548854.py:41: RuntimeWarning: overflow encountered in exp\n",
      "  exp_Z=np.exp(Z)\n",
      "C:\\Users\\Venk\\AppData\\Local\\Temp/ipykernel_15528/3900548854.py:43: RuntimeWarning: invalid value encountered in divide\n",
      "  Yhat=exp_Z/ (exp_Z_mean + 1e-10)\n",
      "C:\\Users\\Venk\\AppData\\Local\\Temp/ipykernel_15528/3900548854.py:45: RuntimeWarning: divide by zero encountered in log\n",
      "  logYhat = np.log(Yhat)\n",
      "C:\\Users\\Venk\\AppData\\Local\\Temp/ipykernel_15528/3900548854.py:46: RuntimeWarning: invalid value encountered in multiply\n",
      "  loss = -np.sum(Y * logYhat) / X.shape[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fce per epoch is=nan\n",
      "Fce per epoch is=57.190008244440776\n",
      "Fce per epoch is=42.939012862181094\n",
      "Fce per epoch is=50.83587624582276\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=60.897954927929256\n",
      "Fce per epoch is=45.0110407460903\n",
      "Fce per epoch is=53.51681501678541\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=53.48202312579685\n",
      "Fce per epoch is=40.86698191568013\n",
      "Fce per epoch is=48.15492346421444\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=40.60181361630742\n",
      "Fce per epoch is=49.40616669394878\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=44.05776257949421\n",
      "Fce per epoch is=54.29123155144308\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=46.217725810540955\n",
      "Fce per epoch is=57.344373530442645\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=41.897795601567694\n",
      "Fce per epoch is=51.238071451742805\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=43.17211330336208\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=38.43370571751031\n",
      "Fce per epoch is=40.609325196225434\n",
      "Fce per epoch is=41.35467263670466\n",
      "Fce per epoch is=49.39965250859902\n",
      "Fce per epoch is=46.08017874585924\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=47.18655966081804\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=41.557006667965844\n",
      "Fce per epoch is=44.065241345083535\n",
      "Fce per epoch is=44.80216211103572\n",
      "Fce per epoch is=54.28455233741878\n",
      "Fce per epoch is=50.88805780944525\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=49.695564896533156\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=43.50906743387722\n",
      "Fce per epoch is=46.22518406014734\n",
      "Fce per epoch is=46.956833287131595\n",
      "Fce per epoch is=57.33759111382987\n",
      "Fce per epoch is=53.89293541442852\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=44.67753616535911\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=39.60494411119061\n",
      "Fce per epoch is=41.9052948777342\n",
      "Fce per epoch is=42.64748343851233\n",
      "Fce per epoch is=51.231495394409514\n",
      "Fce per epoch is=47.88314419702822\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=47.07614181964462\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=38.858589545869336\n",
      "Fce per epoch is=42.97706027411716\n",
      "Fce per epoch is=43.828582170441194\n",
      "Fce per epoch is=55.43189101801787\n",
      "Fce per epoch is=51.896904390370956\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=51.92212517902499\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=42.0629367706054\n",
      "Fce per epoch is=46.803405701419\n",
      "Fce per epoch is=47.63898609496168\n",
      "Fce per epoch is=61.85617058612344\n",
      "Fce per epoch is=58.17760756012517\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=54.950829542721\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=44.06565064868975\n",
      "Fce per epoch is=49.19486474619869\n",
      "Fce per epoch is=50.0204748808623\n",
      "Fce per epoch is=65.87130784363751\n",
      "Fce per epoch is=62.10297316364737\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=48.89339371081836\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=40.060220479155575\n",
      "Fce per epoch is=44.411941389499674\n",
      "Fce per epoch is=45.25748679604944\n",
      "Fce per epoch is=57.84100450360559\n",
      "Fce per epoch is=54.252185127843035\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=51.257213605592526\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=39.62376187773408\n",
      "Fce per epoch is=45.56267857594297\n",
      "Fce per epoch is=46.54634507011461\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=57.190008244440776\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=42.939012862181094\n",
      "Fce per epoch is=49.87857213700495\n",
      "Fce per epoch is=50.83587624582276\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=60.897954927929256\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=45.0110407460903\n",
      "Fce per epoch is=52.57599647709526\n",
      "Fce per epoch is=53.51681501678541\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=53.48202312579685\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=40.86698191568013\n",
      "Fce per epoch is=47.18114076955347\n",
      "Fce per epoch is=48.15492346421444\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=40.60181361630742\n",
      "Fce per epoch is=48.26740804713587\n",
      "Fce per epoch is=49.40616669394878\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=44.05776257949421\n",
      "Fce per epoch is=53.19192920510439\n",
      "Fce per epoch is=54.29123155144308\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=46.217725810540955\n",
      "Fce per epoch is=56.26974309751509\n",
      "Fce per epoch is=57.344373530442645\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=41.897795601567694\n",
      "Fce per epoch is=50.11410621168311\n",
      "Fce per epoch is=51.238071451742805\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=43.17211330336208\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=38.43370571751031\n",
      "Fce per epoch is=40.609325196225434\n",
      "Fce per epoch is=44.24973484861633\n",
      "Fce per epoch is=41.35467263670466\n",
      "Fce per epoch is=49.39965250859902\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=46.08017874585924\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=47.18655966081804\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=41.557006667965844\n",
      "Fce per epoch is=44.065241345083535\n",
      "Fce per epoch is=48.30605943152897\n",
      "Fce per epoch is=44.80216211103572\n",
      "Fce per epoch is=54.28455233741878\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=50.88805780944525\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=49.695564896533156\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=43.50906743387722\n",
      "Fce per epoch is=46.22518406014734\n",
      "Fce per epoch is=50.84125434152155\n",
      "Fce per epoch is=46.956833287131595\n",
      "Fce per epoch is=57.33759111382987\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=53.89293541442852\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=44.67753616535911\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=39.60494411119061\n",
      "Fce per epoch is=41.9052948777342\n",
      "Fce per epoch is=45.77085840282507\n",
      "Fce per epoch is=42.64748343851233\n",
      "Fce per epoch is=51.231495394409514\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=47.88314419702822\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=47.07614181964462\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=38.858589545869336\n",
      "Fce per epoch is=42.97706027411716\n",
      "Fce per epoch is=48.283531192817364\n",
      "Fce per epoch is=43.828582170441194\n",
      "Fce per epoch is=55.43189101801787\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=51.896904390370956\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=51.92212517902499\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=42.0629367706054\n",
      "Fce per epoch is=46.803405701419\n",
      "Fce per epoch is=53.20781924795181\n",
      "Fce per epoch is=47.63898609496168\n",
      "Fce per epoch is=61.85617058612344\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=58.17760756012517\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=54.950829542721\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=44.06565064868975\n",
      "Fce per epoch is=49.19486474619869\n",
      "Fce per epoch is=56.285487431083084\n",
      "Fce per epoch is=50.0204748808623\n",
      "Fce per epoch is=65.87130784363751\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=62.10297316364737\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=48.89339371081836\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=40.060220479155575\n",
      "Fce per epoch is=44.411941389499674\n",
      "Fce per epoch is=50.13014194841914\n",
      "Fce per epoch is=45.25748679604944\n",
      "Fce per epoch is=57.84100450360559\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=54.252185127843035\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=51.257213605592526\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=39.62376187773408\n",
      "Fce per epoch is=45.56267857594297\n",
      "Fce per epoch is=52.543629865589985\n",
      "Fce per epoch is=46.54634507011461\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=57.190008244440776\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=nan\n",
      "Fce per epoch is=42.939012862181094\n",
      "Fce per epoch is=49.87857213700495\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15528/4083625926.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmini_batch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15528/1910065897.py\u001b[0m in \u001b[0;36mtrainer\u001b[1;34m(epochs, lr, alphas, mini_batch, Xtrain, w, b)\u001b[0m\n\u001b[0;32m      4\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0malpha\u001b[0m \u001b[1;32min\u001b[0m \u001b[0malphas\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mmb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmini_batch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m                     \u001b[0mSGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#f, w, b =\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15528/3900548854.py\u001b[0m in \u001b[0;36mSGD\u001b[1;34m(epoch, lr, alpha, mb, Xtrain, w, b)\u001b[0m\n\u001b[0;32m     76\u001b[0m                 \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_b\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m             \u001b[0mFce_per_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m             \u001b[0mreg_term\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[0mFce_per_epoch\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[0mreg_term\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15528/3900548854.py\u001b[0m in \u001b[0;36mFce\u001b[1;34m(X, w, Y, b, alpha)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mFce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m     \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m     \u001b[1;31m# # print(z)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[1;31m# exp_Z = np.exp(z)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Applications\\Python\\lib\\site-packages\\numpy\\core\\overrides.py\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer(num_epoch, epsilon, alpha, mini_batch_size, Xtrain, w, bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4rc1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
